import { Handler } from '@netlify/functions';
import { Client, validateSignature, WebhookEvent } from '@line/bot-sdk';
import { createClient } from '@supabase/supabase-js';
import OpenAI from 'openai';
import { GoogleGenerativeAI } from '@google/generative-ai';
import fetch from 'node-fetch';

const supabase = createClient(
  process.env.SUPABASE_URL || '',
  process.env.SUPABASE_SERVICE_ROLE_KEY || ''
);

export const handler: Handler = async (event) => {
  if (event.httpMethod !== 'POST') return { statusCode: 405, body: 'Method Not Allowed' };

  const { data: settings, error: settingsError } = await supabase.from('settings').select('*').single();
  if (settingsError || !settings) return { statusCode: 500, body: 'Failed to fetch settings' };

  const lineClient = new Client({
    channelAccessToken: settings.line_channel_access_token,
    channelSecret: settings.line_channel_secret,
  });

  const signature = event.headers['x-line-signature'] || '';
  if (!validateSignature(event.body || '', settings.line_channel_secret, signature)) {
    return { statusCode: 401, body: 'Invalid signature' };
  }

  const events: WebhookEvent[] = JSON.parse(event.body || '').events;

  for (const lineEvent of events) {
    if (lineEvent.type === 'message' && lineEvent.message.type === 'text') {
      const userId = lineEvent.source.userId!;
      const userMessage = lineEvent.message.text;

      // æª¢æŸ¥ç”¨æˆ¶ç‹€æ…‹ (æ˜¯å¦åœ¨çœŸäººæ¨¡å¼)
      const { data: userState } = await supabase.from('user_states').select('*').eq('line_user_id', userId).single();
      
      // ä¿®æ­£ï¼šéæ¿¾æ‰ç©ºå­—ä¸²ï¼Œç¢ºä¿ä¸æœƒå› ç‚ºç©ºé—œéµå­—è€Œèª¤è§¸
      const handoverKeywords = settings.handover_keywords
        ?.split(',')
        .map((k: string) => k.trim())
        .filter((k: string) => k !== '') || [];
      
      const isKeywordHit = handoverKeywords.some((k: string) => userMessage.includes(k));

      // å†·å»æ©Ÿåˆ¶ï¼šå¦‚æœ 3 åˆ†é˜å…§æ‰å‰›æ‰‹å‹•é‡è¨­éï¼Œå‰‡å¿½ç•¥é—œéµå­—åµæ¸¬
      let isCooldown = false;
      if (userState?.last_ai_reset_at) {
        const lastReset = new Date(userState.last_ai_reset_at).getTime();
        if (new Date().getTime() - lastReset < 3 * 60 * 1000) {
          isCooldown = true;
        }
      }

      if (handoverKeywords.length > 0 && isKeywordHit && !isCooldown) {
        let nickname = 'åŒ¿åç”¨æˆ¶';
        try { const p = await lineClient.getProfile(userId); nickname = p.displayName; } catch (e) {}
        await supabase.from('user_states').upsert({ line_user_id: userId, nickname, is_human_mode: true, last_human_interaction: new Date().toISOString() });
        await lineClient.replyMessage(lineEvent.replyToken, { type: 'text', text: 'å·²ç‚ºæ‚¨è½‰æ¥çœŸäººå®¢æœï¼Œè«‹ç¨å€™ã€‚' });
        const agentIds = settings.agent_user_ids?.split(',').map((id: string) => id.trim()).filter(Boolean);
        if (agentIds) {
          for (const id of agentIds) {
            try { await lineClient.pushMessage(id, { type: 'text', text: `ğŸ”” çœŸäººé€šçŸ¥ï¼šã€${nickname}ã€‘æ­£åœ¨å‘¼å«å°ˆäººã€‚` }); } catch (e) {}
          }
        }
        continue;
      }

      if (userState?.is_human_mode) {
        const last = new Date(userState.last_human_interaction).getTime();
        if (new Date().getTime() - last < settings.handover_timeout_minutes * 60 * 1000) continue;
        await supabase.from('user_states').update({ is_human_mode: false }).eq('line_user_id', userId);
      }

      if (!settings.is_ai_enabled) continue;

      // å› ç‚ºä¸å„²å­˜å°è©±ç´€éŒ„ï¼Œé€™è£¡ä¸å†æŠ“å– history
      let aiResult: { text: string, id?: string } = { text: '' };
      try {
        if (settings.active_ai === 'gpt') aiResult = await callGPT(settings, [], userMessage);
        else aiResult = { text: await callGemini(settings, [], userMessage) };
      } catch (e: any) {
        aiResult = { text: `âŒ AI éŒ¯èª¤ï¼š
${e.message}` };
      }

      if (aiResult.text) {
        await lineClient.replyMessage(lineEvent.replyToken, { type: 'text', text: aiResult.text });
      }
    }
  }
  return { statusCode: 200, body: 'OK' };
};

async function callGPT(settings: any, history: any[], currentMessage: string) {
  const isGPT5 = settings.gpt_model_name.includes('gpt-5');
  let fileContent = '';
  if (settings.reference_file_url) {
    try { const r = await fetch(settings.reference_file_url); if (r.ok) fileContent = await r.text(); } catch (e) {}
  }
  const systemContent = `${settings.system_prompt}\n\nåƒè€ƒæ–‡å­—ï¼š\n${settings.reference_text}\n\næª”æ¡ˆå…§å®¹ï¼š\n${fileContent}`;

  if (isGPT5) {
    const body: any = {
      model: settings.gpt_model_name,
      input: `System: ${systemContent}\nUser: ${currentMessage}`,
      reasoning: { effort: settings.gpt_reasoning_effort || 'none' },
      text: { verbosity: settings.gpt_verbosity || 'medium' }
    };
    const res = await fetch('https://api.openai.com/v1/responses', {
      method: 'POST',
      headers: { 'Authorization': `Bearer ${settings.gpt_api_key}`, 'Content-Type': 'application/json' },
      body: JSON.stringify(body)
    });
    const result: any = await res.json();
    if (!res.ok || result.error) throw new Error(result.error?.message || res.statusText);
    return { text: result.output?.text || '', id: result.id };
  }

  const openai = new OpenAI({ apiKey: settings.gpt_api_key });
  const messages: any[] = [{ role: 'system', content: systemContent }, { role: 'user', content: currentMessage }];
  const params: any = { model: settings.gpt_model_name, messages };
  if (settings.gpt_model_name.startsWith('o1') || settings.gpt_model_name.startsWith('o3')) {
    params.max_completion_tokens = settings.gpt_max_tokens;
  } else {
    params.max_tokens = settings.gpt_max_tokens;
    params.temperature = settings.gpt_temperature;
  }
  const completion = await openai.chat.completions.create(params);
  return { text: completion.choices[0].message.content || '', id: completion.id };
}

async function callGemini(settings: any, history: any[], currentMessage: string) {
  let filePart: any = null;
  if (settings.reference_file_url) {
    try {
      const r = await fetch(settings.reference_file_url);
      if (r.ok) {
        const b = await r.arrayBuffer();
        filePart = { inline_data: { data: Buffer.from(b).toString('base64'), mime_type: settings.reference_file_url.endsWith('.pdf') ? 'application/pdf' : 'text/plain' } };
      }
    } catch (e) {}
  }
  const userParts: any[] = [{ text: `System: ${settings.system_prompt}\nReference: ${settings.reference_text}` }];
  if (filePart) userParts.push(filePart);
  userParts.push({ text: `User: ${currentMessage}` });
  const contents = [{ role: 'user', parts: userParts }];

  const generationConfig: any = { temperature: settings.gemini_temperature || 1.0, maxOutputTokens: settings.gemini_max_tokens };
  if (settings.gemini_model_name.includes('gemini-3')) {
    generationConfig.thinking_config = { include_thoughts: true, thinking_level: settings.gemini_thinking_level || 'high' };
  }

  const res = await fetch(`https://generativelanguage.googleapis.com/v1beta/models/${settings.gemini_model_name}:generateContent?key=${settings.gemini_api_key}`, {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({ contents, generationConfig })
  });
  const result: any = await res.json();
  if (!res.ok || result.error) throw new Error(result.error?.message || 'Gemini API Error');
  return result.candidates?.[0]?.content?.parts?.find((p: any) => p.text)?.text || '';
}